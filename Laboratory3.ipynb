{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costa Rica Institute of Technology\n",
    "* Course: MP-6122 Pattern Recognition\n",
    "* Student: Jose Martinez Hdez\n",
    "* Year: 2022\n",
    "* Laboratory 3: CNN and ANN - MNIST Classification in Keras using a Jetson Nano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "According to the [NVIDIA Jetson documentation](https://developer.nvidia.com/embedded/jetson-nano-developer-kit). NVIDIA® Jetson Nano™ Developer Kit is a small, powerful computer that lets you run multiple neural networks in parallel for applications like image classification, object detection, segmentation, and speech processing. All in an easy-to-use platform that runs in as little as 5 watts. The Jetson Nano could be seen in the following image:\n",
    "\n",
    "![jetson](https://drive.google.com/uc?id=12J9vuJEO6vF4UJJVMt2Os0fDUtnb7rFb)\n",
    "\n",
    "This board has the following I/O ports: \n",
    "\n",
    "1. microSD card slot for main storage\n",
    "2. 40-pin expansion header\n",
    "3. Micro-USB port for 5V power input, or for Device Mode\n",
    "4. Gigabit Ethernet port\n",
    "5. USB 3.0 ports (x4)\n",
    "6. HDMI output port\n",
    "7. DisplayPort connector\n",
    "8. DC Barrel jack for 5V power input\n",
    "9. MIPI CSI-2 camera connectors\n",
    "\n",
    "And the technical specifications are:\n",
    "\n",
    "![tech](https://drive.google.com/uc?id=13SMMkuE5Jh0UkOv1TGAbCL97h40hsIN7)\n",
    "\n",
    "**References**: \n",
    "\n",
    "- https://developer.nvidia.com/embedded/jetson-nano-developer-kit\n",
    "- https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit\n",
    "- https://pyimagesearch.com/2019/05/06/getting-started-with-the-nvidia-jetson-nano/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the NVIDIA Jetson Nano\n",
    "\n",
    "## Prepare for Setup\n",
    "Before you can even boot up your NVIDIA Jetson Nano you need three things:\n",
    "\n",
    "1. A micro-SD card (minimum 16GB), but it is recommended to use a micro-SD card of 32GB or more.\t\n",
    "2. A 5V 2.5A MicroUSB power supply\n",
    "3. An ethernet cable or Wi-Fi usb adapter (Yes, it doesn't have Wi-Fi embedded on it 😭) \n",
    "\n",
    "To go deeper into the details of the Jetson Nano you can read the following article:\n",
    "\n",
    "- https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#prepare\n",
    "\n",
    "## Write Image to the microSD Card\n",
    "\n",
    "To prepare your microSD card, you’ll need a computer with Internet connection and the ability to read and write SD cards, either via a built-in SD card slot or adapter.\n",
    "\n",
    "1. Download the [Jetson Nano Developer Kit SD Card Image](https://developer.nvidia.com/jetson-nano-sd-card-image), and note where it was saved on the computer.\n",
    "2. Write the image to your microSD card by following the instructions below according to your computer’s operating system: Windows, macOS, or Linux.\n",
    "\n",
    "    - [Instructions for Windows](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#collapse-write_windows)\n",
    "    - [Instructions for MacOS](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#collapse-write_macos)\n",
    "    - [Instructions for Linux](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#collapse-write_linux)\n",
    "\n",
    "## Setup and First Boot\n",
    "\n",
    "There are two ways to interact with the developer kit: \n",
    "\n",
    "1. With display, keyboard and mouse attached \n",
    "2. In “headless mode” via connection from another computer.\n",
    "\n",
    "You can conduct the initial setup either way. \n",
    "\n",
    "### Initial Setup with Display Attached\n",
    "\n",
    "1. Insert the microSD card (with system image already written to it) into the slot on the underside of the Jetson Nano module.\n",
    "\n",
    "![sd](https://drive.google.com/uc?id=13YjsTnZE2IVrQpAW45zDpcw4ptfrXnor)\n",
    "\n",
    "2. Set the developer kit on top of the paper stand.\n",
    "3. Power on your computer display and connect it.\n",
    "4. Connect the USB keyboard and mouse.\n",
    "4. Connect your Micro-USB power supply (or see the [Jetson Nano Developer Kit User Guide](https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#) for details about using DC a power supply with a barrel jack connector). The developer kit will power on and boot automatically.\n",
    "\n",
    "In the first boot, a green LED next to the Micro-USB connector will light as soon as the developer kit powers on. When you boot the first time, the developer kit will take you through some initial setup, including:\n",
    "\n",
    "- Review and accept NVIDIA Jetson software EULA\n",
    "- Select system language, keyboard layout, and time zone\n",
    "- Create username, password, and computer name\n",
    "- Select APP partition size—it is recommended to use the max size suggested\n",
    "\n",
    "After logging in, you will see this screen. Congratulations!\n",
    "\n",
    "![screen](https://drive.google.com/uc?id=13YoDJgyMZM2u5BmyvZUAxrYtuvbyiGy2)\n",
    "\n",
    "**References**: \n",
    "\n",
    "- https://developer.nvidia.com/embedded/jetson-nano-developer-kit\n",
    "- https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit\n",
    "- https://pyimagesearch.com/2019/05/06/getting-started-with-the-nvidia-jetson-nano/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the first code in the Jetson Nano\n",
    "\n",
    "To get started, I really recomended to go over these link provided by NVIDIA:\n",
    "\n",
    "\n",
    "- https://developer.nvidia.com/embedded/community/jetson-projects\n",
    "- https://developer.nvidia.com/embedded/learn/jetson-ai-certification-programs#course_outline\n",
    "- https://github.com/dusty-nv/jetson-inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of MNIST model running in the Jetson Nano\n",
    "\n",
    "**Note**: The base code was taken from the following link:\n",
    "\n",
    "- https://github.com/tflearn/tflearn/blob/master/examples/images/convnet_mnist.py\n",
    "- https://github.com/fmezacr/patrones/tree/master/TfLearn_MNIST_ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/jose13/.local/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: scipy in /home/jose13/.local/lib/python3.8/site-packages (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/jose13/.local/lib/python3.8/site-packages (from scipy) (1.22.3)\n",
      "Requirement already satisfied: numpy in /home/jose13/.local/lib/python3.8/site-packages (1.22.3)\n",
      "Requirement already satisfied: tensorflow in /home/jose13/.local/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/jose13/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/jose13/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/jose13/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jose13/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/jose13/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jose13/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/jose13/.local/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jose13/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jose13/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/jose13/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jose13/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/jose13/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/jose13/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jose13/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: opencv-python in /home/jose13/.local/lib/python3.8/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /home/jose13/.local/lib/python3.8/site-packages (from opencv-python) (1.22.3)\n",
      "Requirement already satisfied: tflearn in /home/jose13/.local/lib/python3.8/site-packages (0.5.0)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from tflearn) (7.0.0)\n",
      "Requirement already satisfied: numpy in /home/jose13/.local/lib/python3.8/site-packages (from tflearn) (1.22.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from tflearn) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install scipy\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install opencv-python\n",
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 23:57:14.651599: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-30 23:57:14.651651: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jose13/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Import Numpy, TensorFlow, TFLearn, and MNIST data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import tflearn.datasets.mnist as mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MNIST...\n",
      "Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Downloading MNIST...\n",
      "Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading MNIST...\n",
      "Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading MNIST...\n",
      "Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the training and test data\n",
    "trainX, trainY, testX, testY = mnist.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Function for displaying a training image by it's index in the MNIST set\n",
    "def show_digit(index):\n",
    "    label = trainY[index].argmax(axis=0)\n",
    "    # Reshape 784 array into 28x28 image\n",
    "    image = trainX[index].reshape([28,28])\n",
    "    plt.title('Training data, index: %d,  Label: %d' % (index, label))\n",
    "    plt.imshow(image, cmap='gray_r')\n",
    "    plt.show()\n",
    "    \n",
    "# Display the first (index 0) training image\n",
    "print(trainY[0])\n",
    "show_digit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jose13/.local/lib/python3.8/site-packages/tflearn/initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 23:57:27.041130: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-30 23:57:27.041205: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-30 23:57:27.041286: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jose13): /proc/driver/nvidia/version does not exist\n",
      "2022-04-30 23:57:27.041972: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "\n",
    "# Define the neural network\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    ops.reset_default_graph()\n",
    "    \n",
    "    # Include the input layer, hidden layer(s), and set how you want to train the model\n",
    "    #Inputs\n",
    "    net = tflearn.input_data([None, 784])\n",
    "    \n",
    "    #Hidden layers\n",
    "    net = tflearn.fully_connected(net, 100, activation = 'ReLU')\n",
    "    \n",
    "    #Output\n",
    "    net = tflearn.fully_connected(net, 10, activation = 'softmax')\n",
    "    \n",
    "    net = tflearn.regression(net, optimizer='sgd', learning_rate=0.1, loss='categorical_crossentropy')\n",
    "    \n",
    "    # This model assumes that your network is named \"net\"    \n",
    "    model = tflearn.DNN(net)\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9899  | total loss: \u001b[1m\u001b[32m0.05557\u001b[0m\u001b[0m | time: 2.569s\n",
      "| SGD | epoch: 020 | loss: 0.05557 - acc: 0.9901 -- iter: 49400/49500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9900  | total loss: \u001b[1m\u001b[32m0.05394\u001b[0m\u001b[0m | time: 3.601s\n",
      "| SGD | epoch: 020 | loss: 0.05394 - acc: 0.9901 | val_loss: 0.08683 - val_acc: 0.9755 -- iter: 49500/49500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(trainX, trainY, validation_set=0.1, show_metric=True, batch_size=100, n_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9741\n"
     ]
    }
   ],
   "source": [
    "# Compare the labels that our model predicts with the actual labels\n",
    "\n",
    "# Find the indices of the most confident prediction for each item. That tells us the predicted digit for that sample.\n",
    "predictions = np.array(model.predict(testX)).argmax(axis=1)\n",
    "\n",
    "# Calculate the accuracy, which is the percentage of times the predicated labels matched the actual labels\n",
    "actual = testY.argmax(axis=1)\n",
    "test_accuracy = np.mean(predictions == actual, axis=0)\n",
    "\n",
    "# Print out the result\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/home/jose13/Documents/mp6122/mp6122_patterns/mnist/saved_model/my_model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p mnist/saved_model\n",
    "model.save('mnist/saved_model/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jose13/Documents/mp6122/mp6122_patterns/mnist/saved_model/my_model\n",
      "Test accuracy:  0.9741\n"
     ]
    }
   ],
   "source": [
    "# Reload a fresh Keras model from the saved model:\n",
    "new_model = build_model()\n",
    "new_model.load('mnist/saved_model/my_model')\n",
    "\n",
    "# Compare the labels that our model predicts with the actual labels\n",
    "\n",
    "# Find the indices of the most confident prediction for each item. That tells us the predicted digit for that sample.\n",
    "predictions = np.array(new_model.predict(testX)).argmax(axis=1)\n",
    "\n",
    "# Calculate the accuracy, which is the percentage of times the predicated labels matched the actual labels\n",
    "actual = testY.argmax(axis=1)\n",
    "test_accuracy = np.mean(predictions == actual, axis=0)\n",
    "\n",
    "# Print out the result\n",
    "print(\"Test accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the camera on the Jetson Nano\n",
    "\n",
    "Run the following command to start the camera:\n",
    "\n",
    "``` bash \n",
    "    $ python3 mnist/number_detector.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

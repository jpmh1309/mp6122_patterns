{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costa Rica Institute of Technology\n",
    "* Course: MP-6122 Pattern Recognition\n",
    "* Student: Jose Martinez Hdez\n",
    "* Course: Data Science \n",
    "* Year: 2022\n",
    "* Notebook 2: Supervised Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libaries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code_number  Clump_Thickness  Uniformity_of_Cell_Size  Uniformity_of_Cell_Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class\n",
       "0      1002945                5                        4                         4                  5                            7          10                3                2        1      2\n",
       "1      1015425                3                        1                         1                  1                            2           2                3                1        1      2\n",
       "2      1016277                6                        8                         8                  1                            3           4                3                7        1      2\n",
       "3      1017023                4                        1                         1                  3                            2           1                3                1        1      2\n",
       "4      1017122                8                       10                        10                  8                            7          10                9                7        1      4"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/breast-cancer-wisconsin.data')\n",
    "df.columns = ['code_number', 'Clump_Thickness','Uniformity_of_Cell_Size' ,'Uniformity_of_Cell_Shape', 'Marginal_Adhesion',\n",
    "              'Single_Epithelial_Cell_Size',  'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli' ,'Mitoses','Class']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('?', np.nan)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Class = df.Class.map({2: 0, 4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Class.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['code_number','Class'],axis=1).values\n",
    "Y = df.Class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "df.Class.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017122</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code_number  Clump_Thickness  Uniformity_of_Cell_Size  Uniformity_of_Cell_Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class\n",
       "0      1002945                5                        4                         4                  5                            7          10                3                2        1      0\n",
       "1      1015425                3                        1                         1                  1                            2           2                3                1        1      0\n",
       "2      1016277                6                        8                         8                  1                            3           4                3                7        1      0\n",
       "3      1017023                4                        1                         1                  3                            2           1                3                1        1      0\n",
       "4      1017122                8                       10                        10                  8                            7          10                9                7        1      1"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv('dataset/housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sels = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "x = data.loc[:,column_sels]\n",
    "y = data['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "x = pd.DataFrame(data=min_max_scaler.fit_transform(x), columns=column_sels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (Regression)\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised machine learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "<img src=\"images/linear.png\" width=400 height=400 />\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "From basic linear algebra, we should remember that the linear regression model is a linear combination of the independent variables, that is described by the following equation: \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "Where $b_0$ is the intercept and $b_1$ is the slope.\n",
    "\n",
    "So, the main idea of linear regression is to find the best fit line between the independent and dependent variables. This can be done by finding the value of the slope ($b_1$) and the intercept ($b_0$) in the linear equation that reduces the error between a predicted value from the model and the actual value from the data. \n",
    "\n",
    "We create a hipotetic model by using the following equation:\n",
    "\n",
    "$h(x) = b_0 + b_1 \\cdot x$\n",
    "\n",
    "And then we calculate the error between the actual value and the predicted value by using the following cost equation of the squared error:\n",
    "\n",
    "$J(b_0, b_1) = \\frac{1}{2m} \\sum_{1=n}^{i=1} (h(x_n) - y_n)^2$\n",
    "\n",
    "### Optimal Applications \n",
    "\n",
    "This model has the following assumptions and limitations: \n",
    "\n",
    "1. *Linearity*: The relationship between the dependent and independent variables is linear.\n",
    "2. *Homoscedasticity*: The error is homoscedastic. The variance of the error terms should be constant i.e the spread of residuals should be constant for all values of X. This assumption can be checked by plotting a residual plot. If the assumption is violated then the points will form a funnel shape otherwise they will be constant.\n",
    "3. *Independence*:  The variables should be independent of each other i.e no correlation should be there between the independent variables.\n",
    "4. *Normality*: The $x$ and $y$ variables should be normally distributed.\n",
    "\n",
    "Basically, this model will work well when the assumptions are satisfied. The violation of the assumptions leads to a decrease in the accuracy of the model therefore the predictions are not accurate and error is also high.\n",
    "\n",
    "**References**: \n",
    "\n",
    "- https://towardsdatascience.com/ensemble-models-5a62d4f4cb0chttps://www.analyticsvidhya.com/blog/2021/05/all-you-need-to-know-about-your-first-machine-learning-model-linear-regression/#:~:text=In%20the%20most%20simple%20words,the%20dependent%20and%20independent%20variable.\n",
    "- https://www.youtube.com/watch?v=1-OGRohmH2s\n",
    "- https://towardsdatascience.com/mathematics-for-machine-learning-linear-regression-least-square-regression-de09cf53757c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7406426641094095\n",
      "[ -9.60975755   4.64204584   0.56083933   2.68673382  -8.63457306\n",
      "  19.88368651   0.06721501 -16.22666104   7.03913802  -6.46332721\n",
      "  -8.95582398   3.69282735 -19.01724361]\n",
      "26.620267584687756\n"
     ]
    }
   ],
   "source": [
    "# Example of Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x, y)\n",
    "print(regressor.score(x, y))\n",
    "print(regressor.coef_)\n",
    "print(regressor.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Classification)\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.linear_model import LogisticRegression\\n\\nclassifier = LogisticRegression(random_state=0)\\nclassifier.fit(X_train, y_train)\\nprint(regressor.score(X_train, y_train))\\n'"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of Logistic Regression\n",
    "\n",
    "# Example of Linear Regression\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(regressor.score(X_train, y_train))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (Classification)\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points.\n",
    "\n",
    "![svm](images/svm.png)\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x_1 + b_2 \\cdot x_2 + ... + b_n \\cdot x_n $\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "**References**: \n",
    "\n",
    "- https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models for multi-class classification (Classification)\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x_1 + b_2 \\cdot x_2 + ... + b_n \\cdot x_n $\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Linear Models for multi-class classification\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "### kNN for classification\n",
    "\n",
    "### kNN for regression\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (Classification)\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "In statistics, naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong (naive) independence assumptions between the features (see Bayes classifier). They are among the simplest Bayesian network models, but coupled with kernel density estimation, they can achieve high accuracy levels.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees (Classification)\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests (Classification)\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Support Vector Machines (Classification)\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods\n",
    "\n",
    "**References**: \n",
    "\n",
    "- https://towardsdatascience.com/ensemble-models-5a62d4f4cb0c\n",
    "- https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Ensemble Methods\n",
    "\n",
    "## Max Voting\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "### Example of the model\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* \n",
    "\n",
    "## Averaging\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "### Example of the model\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* \n",
    "\n",
    "## Weighted Average\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "### Example of the model\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of simple emsemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Ensemble Methods\n",
    "\n",
    "## Bagging\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "### Example of the model\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* \n",
    "\n",
    "## Boosting\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "### Example of the model\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* \n",
    "\n",
    "## Stacking\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "### Example of the model\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* \n",
    "\n",
    "## Blending\n",
    "\n",
    "### Conceptual Explanation \n",
    "\n",
    "Linear Regression is the supervised Machine Learning model in which the model finds the best fit linear line between the independent and dependent variable i.e it finds the linear relationship between the dependent and independent variable.\n",
    "\n",
    "### Mathematical \n",
    "\n",
    "$y = b_0 + b_1 \\cdot x$\n",
    "\n",
    "### Optimal Applications\n",
    "\n",
    "### Example of the model\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of advanced emsemble tecnhiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is it possible to create our own ensemble model? If so, how would it be the approach?\n",
    "\n",
    "**References**: \n",
    "\n",
    "- *link* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "Performance metrics are a part of every machine learning pipeline. They tell you if you’re making progress, and put a number on it. All machine learning models, whether it’s linear regression, or a SOTA technique like BERT, need a metric to judge performance\n",
    "\n",
    "**References**: \n",
    "\n",
    "- https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide\n",
    "- https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics\n",
    "\n",
    "Classification models have discrete output, so we need a metric that compares discrete classes in some form. Classification Metrics evaluate a model’s performance and tell you how good or bad the classification is, but each of them evaluates it in a different way.\n",
    "\n",
    "The following are the metrics for evaluating classification problems:\n",
    "\n",
    "- Accuracy\n",
    "- Balanced Accuracy\n",
    "- Top k Accuracy\n",
    "- Average Precision\n",
    "- Brier Score\n",
    "- F1 Score\n",
    "- F1 Micro Score\n",
    "- F1 Macro Score\n",
    "- F1 Weighted Score\n",
    "- F1 Sample Score\n",
    "- Log Loss\n",
    "- Precision\n",
    "- Recall\n",
    "- Jaccard\n",
    "- Roc Auc\n",
    "- Roc Auc Overlap\n",
    "- Roc Auc Under Over\n",
    "\n",
    "In the following seccion, we will discuss more details of the most common metrics.\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "Confusion Matrix is a tabular visualization of the ground-truth labels versus model predictions. Each row of the confusion matrix represents the instances in a predicted class and each column represents the instances in an actual class. Confusion Matrix is not exactly a performance metric but sort of a basis on which other metrics evaluate the results. One example of a confusion matrix is the following image:\n",
    "\n",
    "![confusion](images/confusion.png)\n",
    "\n",
    "The confusion matrix is made up of the following elements:\n",
    "\n",
    "- **True Positives**: Number of correct predictions of the positive class.\n",
    "- **True Negatives**: Number of correct predictions of the negative class.\n",
    "- **False Positives**: Number of incorrect predictions of the positive class.\n",
    "- **False Negatives**: Number of incorrect predictions of the negative class.\n",
    "\n",
    "The idea is to try minimize the **False Positives** and **False Negatives**, since these are the ones that are most likely to be misclassified.\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "Classification accuracy is perhaps the simplest metric to use and implement and is defined as the number of correct predictions divided by the total number of predictions, multiplied by 100.\n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$Accuracy = \\frac{TP + TN}{TP + FP + TN + FN}$ \n",
    "\n",
    "### Precision\n",
    "\n",
    "There are many cases in which classification accuracy is not a good indicator of your model performance. One of these scenarios is when your class distribution is imbalanced (one class is more frequent than others). In this case, even if you predict all samples as the most frequent class you would get a high accuracy rate, which does not make sense at all (because your model is not learning anything, and is just predicting everything as the top class). Precision is the ratio of true positives and total positives predicted. \n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$Precision = \\frac{TP}{TP+FP}$ \n",
    "\n",
    "### Recall\n",
    "\n",
    "Recall is another important metric, which is defined as the fraction of samples from a class which are correctly predicted by the model.\n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$Recall = \\frac{TP}{TP+FN}$ \n",
    "\n",
    "### F1\n",
    "\n",
    "Depending on application, you may want to give higher priority to recall or precision. But there are many applications in which both recall and precision are important. Therefore, it is natural to think of a way to combine these two into a single metric. One popular metric which combines precision and recall is called F1-score, which is the harmonic mean of precision and recall.\n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$F1 = \\frac{1}{\\frac{1}{Precision} + \\frac{1}{Recall}}$ \n",
    "\n",
    "### Receiver Operating Curve (ROC) \n",
    "\n",
    "The receiver operating characteristic curve is plot which shows the performance of a binary classifier as function of its cut-off threshold. It essentially shows the true positive rate (TPR) against the false positive rate (FPR) for various threshold values.\n",
    "\n",
    "One example of a ROC curve is the following image:\n",
    "\n",
    "![roc](images/roc.png)\n",
    "\n",
    "### Area Under the Curve (AUC)\n",
    "\n",
    "The area under the curve (AUC), is an aggregated measure of performance of a binary classifier on all possible threshold values (and therefore it is threshold invariant). AUC calculates the area under the ROC curve, and therefore it is between 0 and 1. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example.\n",
    "\n",
    "One example of a AUC curve is the following image:\n",
    "\n",
    "![auc](images/auc.png)\n",
    "\n",
    "**References**: \n",
    "\n",
    "- https://neptune.ai/blog/performance-metrics-in-machine-learning-complete-guide#:~:text=Classification%20models%20have%20discrete%20output,it%20in%20a%20different%20way.\n",
    "- https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b\n",
    "- https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Example of Classification Metrics\n",
    "# Notebook from: https://app.neptune.ai/theaayushbajaj/sandbox/n/f884bbea-5263-4aeb-aa35-18d74b2835b9/41813125-2b9d-4332-b73f-f07c3b977372\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train a model\n",
    "clf = SVC(\n",
    "        C=1.0,\n",
    "        kernel='rbf',\n",
    "        degree=3,\n",
    "        gamma='scale',\n",
    "        coef0=0.0,\n",
    "        shrinking=True,\n",
    "        probability=False,\n",
    "        tol=0.001,\n",
    "        cache_size=200,\n",
    "        class_weight=None,\n",
    "        verbose=False,\n",
    "        max_iter=-1,\n",
    "        decision_function_shape='ovr',\n",
    "        break_ties=False,\n",
    "        random_state=None\n",
    "    )\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is 0.9635036496350365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Accuracy\n",
    "print(f'Accuracy Score is {accuracy_score(y_test,y_hat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.959184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_hat)\n",
    "print('Precision: %f' % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.940000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_hat)\n",
    "print('Recall: %f' % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.949495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_hat)\n",
    "print('F1 Score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '2-class Precision-Recall curve: AP=0.96')"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "disp = plot_precision_recall_curve(clf, X, Y)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' (Temp/ipykernel_21984/640381356.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\jpmh1\\AppData\\Local\\Temp/ipykernel_21984/640381356.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    ns_probs = [0 for _ in range(len(Y)])\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '('\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ns_probs = [0 for _ in range(len(Y)])\n",
    "\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(Y, ns_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(Y, ns_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics\n",
    "\n",
    "Regression refers to predictive modeling problems that involve predicting a numeric value.\n",
    "\n",
    "It is different from classification that involves predicting a class label. Unlike classification, you cannot use classification accuracy to evaluate the predictions made by a regression model. Instead, you must use error metrics specifically designed for evaluating predictions made on regression problems and it is most Robust to outliers.\n",
    "\n",
    "The following are the metrics for evaluating regression problems:\n",
    "\n",
    "- Max Error\n",
    "- Mean Absolute Error\n",
    "- Mean Squared Error\n",
    "- Root Mean Squared Error\n",
    "- Mean Squared Logarithmic Error\n",
    "- Median Absolute Error\n",
    "- R-Squared\n",
    "- Explained Variance\n",
    "- Mean Poisson Deviance\n",
    "- Mean Gamma Deviance\n",
    "- Mean Absolute Percentage Error\n",
    "\n",
    "In the following seccion, we will discuss more details of the most common metrics.\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "MAE is a very simple metric which calculates the absolute difference between actual and predicted values. It has the advantage that the MAE you get is in the same unit as the output variable.\n",
    "\n",
    "In contrast, the disadvantage is that the graph of MAE is not differentiable so we have to apply various optimizers like gradient descent which can be differentiable.\n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$MAE = \\frac{1}{n} \\sum_{1=n}^{i=1} \\left|h(x_n) - y_n\\right|$\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "\n",
    "It represents the squared distance between actual and predicted values. we perform squared to avoid the cancellation of negative terms and it is the benefit of MSE. MSE is a most used and very simple metric with a little bit of change in mean absolute error. Mean squared error states that finding the squared difference between actual and predicted value.\n",
    "\n",
    "So, above we are finding the absolute difference and here we are finding the squared difference. The graph of MSE is differentiable, so you can easily use it as a loss function.\n",
    "\n",
    "It has the disadvantage that the value you get after calculating MSE is a squared unit of output. For example, the output variable is in meter (m) then after calculating MSE the output we get is in meter squared and if the data has outliers t then it penalizes the outliers most and the calculated MSE is bigger. So, in short, it is not robust to outliers which were an advantage in MAE.\n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$MSE = \\frac{1}{n} \\sum_{1=n}^{i=1} \\left(h(x_n) - y_n\\right)^2$\n",
    "\n",
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "As RMSE is clear by the name itself, that it is a simple square root of mean squared error. It has the advantage that the output value you get is in the same unit as the required output variable which makes interpretation of loss easy, but it is not that robust to outliers as compared to MAE.\n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{1}{n} \\sum_{1=n}^{i=1} \\left(h(x_n) - y_n\\right)^2}$\n",
    "\n",
    "### Root Mean Squared Logarithmic Error (RMSLE)\n",
    "\n",
    "Taking the $\\log$ of the RMSE metric slows down the scale of error. The metric is very helpful when you are developing a model without calling the inputs. In that case, the output will vary on a large scale. To control this situation of RMSE we take the $\\log$  of calculated RMSE error and resultant we get as RMSLE.\n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$RMSLE = \\sqrt{\\frac{1}{n} \\sum_{1=n}^{i=1} \\left( \\log \\left(h(x_n) + 1\\right) - \\log \\left( y_n + 1 \\right) \\right)^2}$\n",
    "\n",
    "### R Squared ($R^2$)\n",
    "\n",
    "$R^2$ score is a metric that tells the performance of your model, not the loss in an absolute sense that how many wells did your model perform. In contrast, MAE and MSE depend on the context as we have seen whereas the R2 score is independent of context.\n",
    "\n",
    "So, with help of R squared we have a baseline model to compare a model which none of the other metrics provides. The same we have in classification problems which we call a threshold which is fixed at 0.5. So basically R2 squared calculates how must regression line is better than a mean line.\n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$R^2 = 1 - \\frac{RSS}{TSS}$ \n",
    "\n",
    "Where RSS is the Residual Sum of Squares and TSS is the Total Sum of Squares. They are described with the following formulas:\n",
    "\n",
    "$RSS =  \\sum_{1=n}^{i=1} \\left(h(x_n) - y_n\\right)^2$ \n",
    "\n",
    "$TSS =  \\sum_{1=n}^{i=1} \\left(h(x_n) - \\overline{y}\\right)^2 $ \n",
    "\n",
    "### Adjusted R Squared\n",
    "\n",
    "The disadvantage of the R2 score is while adding new features in data the R2 score starts increasing or remains constant but it never decreases because It assumes that while adding more data variance of data increases.\n",
    "\n",
    "But the problem is when we add an irrelevant feature in the dataset then at that time R2 sometimes starts increasing which is incorrect. Hence, To control this situation adjusted R Squared came into existence.\n",
    "\n",
    "This metric is described with the following equation:\n",
    "\n",
    "$R^2_a = 1 - \\left| \\left( \\frac{n-1}{n-k-1}\\right) \\times  \\left(1 - R2\\right) \\right|$ \n",
    "\n",
    "Where $k$ is the number of independent variables, $n$ is the number of observations, and $R^2$ is the R squared value.\n",
    "\n",
    "**References**: \n",
    "\n",
    "- https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce\n",
    "- https://machinelearningmastery.com/regression-metrics-for-machine-learning/\n",
    "- https://www.analyticsvidhya.com/blog/2021/05/know-the-best-evaluation-metrics-for-your-regression-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Example of Regression Metrics\n",
    "# Notebook from: https://app.neptune.ai/theaayushbajaj/sandbox/n/f884bbea-5263-4aeb-aa35-18d74b2835b9/41813125-2b9d-4332-b73f-f07c3b977372\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x, y)\n",
    "y_hat = regressor.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3.27 (+/- 3.35)\n"
     ]
    }
   ],
   "source": [
    "mae = np.abs(y-y_hat)\n",
    "\n",
    "print(f\"MAE: {mae.mean():0.2f} (+/- {mae.std():0.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 21.89 (+/- 59.14)\n"
     ]
    }
   ],
   "source": [
    "mse = (y-y_hat)**2\n",
    "\n",
    "print(f\"MSE: {mse.mean():0.2f} (+/- {mse.std():0.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.68\n"
     ]
    }
   ],
   "source": [
    "mse = (y-y_hat)**2\n",
    "\n",
    "rmse = np.sqrt(mse.mean())\n",
    "\n",
    "print(f\"RMSE: {rmse:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 coefficient of determination: 74.06%\n"
     ]
    }
   ],
   "source": [
    "# R^2 coefficient of determination\n",
    "SE_line = sum((y-y_hat)**2)\n",
    "SE_mean = sum((y-y.mean())**2)\n",
    "\n",
    "r2 = 1-(SE_line/SE_mean)\n",
    "\n",
    "print(f\"R^2 coefficient of determination: {r2*100:0.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "762531c616344ec89a3ae3efe707c5228b11104740e698ce334efdf481e7418a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

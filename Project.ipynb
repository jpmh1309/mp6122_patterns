{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costa Rica Institute of Technology\n",
    "* Course: MP-6122 Pattern Recognition\n",
    "* Student: Jose Martinez Hdez\n",
    "* Year: 2022\n",
    "* Project: Human Detection Using the Yolo Dataset and the Jason Nano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**: \n",
    "\n",
    "- https://github.com/pjreddie/darknet\n",
    "- https://arxiv.org/abs/1506.02640\n",
    "- https://towardsdatascience.com/yolo-you-only-look-once-real-time-object-detection-explained-\n",
    "- https://arxiv.org/pdf/1805.00123.pdf\n",
    "- https://arxiv.org/pdf/2204.06846v1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Detection\n",
    "\n",
    "Detecting people in images or videos is among the most important components of computer vision and has attracted increasing attention in recent years.  A system that is able to detect human accurately plays an essential role in applications such as autonomous cars, smart surveillance, robotics, and advanced human machine interactions\n",
    "\n",
    "The problem could be addressed in different ways, such as using a neural network, a deep learning framework, or a combination of both.  In this project, we will use the YOLO algorithm to detect humans in images or videos.\n",
    "\n",
    "![detection](https://drive.google.com/uc?id=1FO3vz15hJeTZAEoP_yHK7PbvLyRcQRBy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO\n",
    "\n",
    "YOLO stands for You Only Look Once, and it's an algorithm for real-time object detection and recognition in images. The algorithm was proposed by Redmond et. al in a paper first published at the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) in 2015. The paper won the OpenCV People’s Choice Award.\n",
    "\n",
    "Compared to the approach taken by object detection algorithms before YOLO, which repurpose classifiers to perform detection, YOLO proposes the use of an end-to-end neural network that makes predictions of bounding boxes and class probabilities all at once.\n",
    "\n",
    "For further details, please refer to the paper, which is the original source of the algorithm:\n",
    "\n",
    "- https://arxiv.org/pdf/1506.02640v5.pdf\n",
    "\n",
    "**References**: \n",
    "\n",
    "- https://medium.com/analytics-vidhya/yolo-explained-5b6f4564f31\n",
    "- https://pjreddie.com/darknet/yolo/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This project\n",
    "\n",
    "The goal of this project is to implement a basic YOLO algorithm that can detect humans in images or videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a pre-trained YOLO model\n",
    "\n",
    "Fisrt, let´s go through detecting objects with the YOLO system using a pre-trained model.\n",
    "\n",
    "Go to the folder project/pretrained and download the darknet repository.\n",
    "\n",
    "```bash\n",
    "    cd project/pretrained\n",
    "    git clone https://github.com/pjreddie/darknet\n",
    "    cd darknet\n",
    "    make\n",
    "```\n",
    "\n",
    "Then download the pre-trained model:\n",
    "\n",
    "```bash\n",
    "    wget https://pjreddie.com/media/files/yolov3.weights\n",
    "```\n",
    "\n",
    "Then run the detector!\n",
    "\n",
    "```bash\n",
    "    ./darknet detect cfg/yolov3.cfg yolov3.weights data/dog.jpg\n",
    "```\n",
    "\n",
    "By running this command, we will get:\n",
    "\n",
    "```console\n",
    "    Loading weights from yolov3.weights...Done!\n",
    "    data/dog.jpg: Predicted in 25.196584 seconds.\n",
    "    dog: 100%\n",
    "    truck: 92%\n",
    "    bicycle: 99%\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using our own YOLO model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
